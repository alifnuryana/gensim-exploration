{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gensim Exploration",
   "id": "cfe0158984ae2664"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import all the necessary libraries",
   "id": "5ce5004dcc41c715"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.149669Z",
     "start_time": "2024-09-06T16:43:18.759476Z"
    }
   },
   "source": [
    "import gensim\n",
    "from pprint import pprint"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare the data",
   "id": "338bc6358c35a4d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.155152Z",
     "start_time": "2024-09-06T16:43:19.152750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_corpus = [\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "]\n",
    "\n",
    "pprint(t_corpus)"
   ],
   "id": "82bfb7c1cb7cd60d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A survey of user opinion of computer system response time',\n",
      " 'Relation of user perceived response time to error measurement',\n",
      " 'The generation of random binary unordered trees',\n",
      " 'The intersection graph of paths in trees',\n",
      " 'Graph minors IV Widths of trees and well quasi ordering']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare the stop words ",
   "id": "10c3540a88252e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.260546Z",
     "start_time": "2024-09-06T16:43:19.256702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stoplist = set(gensim.parsing.preprocessing.STOPWORDS)\n",
    "pprint(stoplist)"
   ],
   "id": "ae3297d313c98826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a',\n",
      " 'about',\n",
      " 'above',\n",
      " 'across',\n",
      " 'after',\n",
      " 'afterwards',\n",
      " 'again',\n",
      " 'against',\n",
      " 'all',\n",
      " 'almost',\n",
      " 'alone',\n",
      " 'along',\n",
      " 'already',\n",
      " 'also',\n",
      " 'although',\n",
      " 'always',\n",
      " 'am',\n",
      " 'among',\n",
      " 'amongst',\n",
      " 'amoungst',\n",
      " 'amount',\n",
      " 'an',\n",
      " 'and',\n",
      " 'another',\n",
      " 'any',\n",
      " 'anyhow',\n",
      " 'anyone',\n",
      " 'anything',\n",
      " 'anyway',\n",
      " 'anywhere',\n",
      " 'are',\n",
      " 'around',\n",
      " 'as',\n",
      " 'at',\n",
      " 'back',\n",
      " 'be',\n",
      " 'became',\n",
      " 'because',\n",
      " 'become',\n",
      " 'becomes',\n",
      " 'becoming',\n",
      " 'been',\n",
      " 'before',\n",
      " 'beforehand',\n",
      " 'behind',\n",
      " 'being',\n",
      " 'below',\n",
      " 'beside',\n",
      " 'besides',\n",
      " 'between',\n",
      " 'beyond',\n",
      " 'bill',\n",
      " 'both',\n",
      " 'bottom',\n",
      " 'but',\n",
      " 'by',\n",
      " 'call',\n",
      " 'can',\n",
      " 'cannot',\n",
      " 'cant',\n",
      " 'co',\n",
      " 'computer',\n",
      " 'con',\n",
      " 'could',\n",
      " 'couldnt',\n",
      " 'cry',\n",
      " 'de',\n",
      " 'describe',\n",
      " 'detail',\n",
      " 'did',\n",
      " 'didn',\n",
      " 'do',\n",
      " 'does',\n",
      " 'doesn',\n",
      " 'doing',\n",
      " 'don',\n",
      " 'done',\n",
      " 'down',\n",
      " 'due',\n",
      " 'during',\n",
      " 'each',\n",
      " 'eg',\n",
      " 'eight',\n",
      " 'either',\n",
      " 'eleven',\n",
      " 'else',\n",
      " 'elsewhere',\n",
      " 'empty',\n",
      " 'enough',\n",
      " 'etc',\n",
      " 'even',\n",
      " 'ever',\n",
      " 'every',\n",
      " 'everyone',\n",
      " 'everything',\n",
      " 'everywhere',\n",
      " 'except',\n",
      " 'few',\n",
      " 'fifteen',\n",
      " 'fifty',\n",
      " 'fill',\n",
      " 'find',\n",
      " 'fire',\n",
      " 'first',\n",
      " 'five',\n",
      " 'for',\n",
      " 'former',\n",
      " 'formerly',\n",
      " 'forty',\n",
      " 'found',\n",
      " 'four',\n",
      " 'from',\n",
      " 'front',\n",
      " 'full',\n",
      " 'further',\n",
      " 'get',\n",
      " 'give',\n",
      " 'go',\n",
      " 'had',\n",
      " 'has',\n",
      " 'hasnt',\n",
      " 'have',\n",
      " 'he',\n",
      " 'hence',\n",
      " 'her',\n",
      " 'here',\n",
      " 'hereafter',\n",
      " 'hereby',\n",
      " 'herein',\n",
      " 'hereupon',\n",
      " 'hers',\n",
      " 'herself',\n",
      " 'him',\n",
      " 'himself',\n",
      " 'his',\n",
      " 'how',\n",
      " 'however',\n",
      " 'hundred',\n",
      " 'i',\n",
      " 'ie',\n",
      " 'if',\n",
      " 'in',\n",
      " 'inc',\n",
      " 'indeed',\n",
      " 'interest',\n",
      " 'into',\n",
      " 'is',\n",
      " 'it',\n",
      " 'its',\n",
      " 'itself',\n",
      " 'just',\n",
      " 'keep',\n",
      " 'kg',\n",
      " 'km',\n",
      " 'last',\n",
      " 'latter',\n",
      " 'latterly',\n",
      " 'least',\n",
      " 'less',\n",
      " 'ltd',\n",
      " 'made',\n",
      " 'make',\n",
      " 'many',\n",
      " 'may',\n",
      " 'me',\n",
      " 'meanwhile',\n",
      " 'might',\n",
      " 'mill',\n",
      " 'mine',\n",
      " 'more',\n",
      " 'moreover',\n",
      " 'most',\n",
      " 'mostly',\n",
      " 'move',\n",
      " 'much',\n",
      " 'must',\n",
      " 'my',\n",
      " 'myself',\n",
      " 'name',\n",
      " 'namely',\n",
      " 'neither',\n",
      " 'never',\n",
      " 'nevertheless',\n",
      " 'next',\n",
      " 'nine',\n",
      " 'no',\n",
      " 'nobody',\n",
      " 'none',\n",
      " 'noone',\n",
      " 'nor',\n",
      " 'not',\n",
      " 'nothing',\n",
      " 'now',\n",
      " 'nowhere',\n",
      " 'of',\n",
      " 'off',\n",
      " 'often',\n",
      " 'on',\n",
      " 'once',\n",
      " 'one',\n",
      " 'only',\n",
      " 'onto',\n",
      " 'or',\n",
      " 'other',\n",
      " 'others',\n",
      " 'otherwise',\n",
      " 'our',\n",
      " 'ours',\n",
      " 'ourselves',\n",
      " 'out',\n",
      " 'over',\n",
      " 'own',\n",
      " 'part',\n",
      " 'per',\n",
      " 'perhaps',\n",
      " 'please',\n",
      " 'put',\n",
      " 'quite',\n",
      " 'rather',\n",
      " 're',\n",
      " 'really',\n",
      " 'regarding',\n",
      " 'same',\n",
      " 'say',\n",
      " 'see',\n",
      " 'seem',\n",
      " 'seemed',\n",
      " 'seeming',\n",
      " 'seems',\n",
      " 'serious',\n",
      " 'several',\n",
      " 'she',\n",
      " 'should',\n",
      " 'show',\n",
      " 'side',\n",
      " 'since',\n",
      " 'sincere',\n",
      " 'six',\n",
      " 'sixty',\n",
      " 'so',\n",
      " 'some',\n",
      " 'somehow',\n",
      " 'someone',\n",
      " 'something',\n",
      " 'sometime',\n",
      " 'sometimes',\n",
      " 'somewhere',\n",
      " 'still',\n",
      " 'such',\n",
      " 'system',\n",
      " 'take',\n",
      " 'ten',\n",
      " 'than',\n",
      " 'that',\n",
      " 'the',\n",
      " 'their',\n",
      " 'them',\n",
      " 'themselves',\n",
      " 'then',\n",
      " 'thence',\n",
      " 'there',\n",
      " 'thereafter',\n",
      " 'thereby',\n",
      " 'therefore',\n",
      " 'therein',\n",
      " 'thereupon',\n",
      " 'these',\n",
      " 'they',\n",
      " 'thick',\n",
      " 'thin',\n",
      " 'third',\n",
      " 'this',\n",
      " 'those',\n",
      " 'though',\n",
      " 'three',\n",
      " 'through',\n",
      " 'throughout',\n",
      " 'thru',\n",
      " 'thus',\n",
      " 'to',\n",
      " 'together',\n",
      " 'too',\n",
      " 'top',\n",
      " 'toward',\n",
      " 'towards',\n",
      " 'twelve',\n",
      " 'twenty',\n",
      " 'two',\n",
      " 'un',\n",
      " 'under',\n",
      " 'unless',\n",
      " 'until',\n",
      " 'up',\n",
      " 'upon',\n",
      " 'us',\n",
      " 'used',\n",
      " 'using',\n",
      " 'various',\n",
      " 'very',\n",
      " 'via',\n",
      " 'was',\n",
      " 'we',\n",
      " 'well',\n",
      " 'were',\n",
      " 'what',\n",
      " 'whatever',\n",
      " 'when',\n",
      " 'whence',\n",
      " 'whenever',\n",
      " 'where',\n",
      " 'whereafter',\n",
      " 'whereas',\n",
      " 'whereby',\n",
      " 'wherein',\n",
      " 'whereupon',\n",
      " 'wherever',\n",
      " 'whether',\n",
      " 'which',\n",
      " 'while',\n",
      " 'whither',\n",
      " 'who',\n",
      " 'whoever',\n",
      " 'whole',\n",
      " 'whom',\n",
      " 'whose',\n",
      " 'why',\n",
      " 'will',\n",
      " 'with',\n",
      " 'within',\n",
      " 'without',\n",
      " 'would',\n",
      " 'yet',\n",
      " 'you',\n",
      " 'your',\n",
      " 'yours',\n",
      " 'yourself',\n",
      " 'yourselves'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess the data\n",
    "Preprocess the data by removing the stop words and use the simple_preprocess function to tokenize the data.\n",
    "the simple_preprocess function will convert a document into a list of tokens."
   ],
   "id": "f9338e98fe5ad313"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.364266Z",
     "start_time": "2024-09-06T16:43:19.361478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_corpus = [\n",
    "    [word for word in gensim.utils.simple_preprocess(document, deacc=True) if word not in stoplist]\n",
    "    for document in t_corpus\n",
    "]\n",
    "\n",
    "pprint(processed_corpus)"
   ],
   "id": "d3a7fa214f43244d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['survey', 'user', 'opinion', 'response', 'time'],\n",
      " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
      " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
      " ['intersection', 'graph', 'paths', 'trees'],\n",
      " ['graph', 'minors', 'iv', 'widths', 'trees', 'quasi', 'ordering']]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create the dictionary\n",
    "\n",
    "Dictionary encapsulates the mapping between normalized words and their integer ids. It is used to determine the vocabulary size, as well as for debugging and topic printing."
   ],
   "id": "f83c2aace3bdda62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.414016Z",
     "start_time": "2024-09-06T16:43:19.411027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_corpus)\n",
    "pprint(dictionary.token2id)\n",
    "print(dictionary)"
   ],
   "id": "7b6fac7c64082391",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'binary': 9,\n",
      " 'error': 5,\n",
      " 'generation': 10,\n",
      " 'graph': 14,\n",
      " 'intersection': 15,\n",
      " 'iv': 17,\n",
      " 'measurement': 6,\n",
      " 'minors': 18,\n",
      " 'opinion': 0,\n",
      " 'ordering': 19,\n",
      " 'paths': 16,\n",
      " 'perceived': 7,\n",
      " 'quasi': 20,\n",
      " 'random': 11,\n",
      " 'relation': 8,\n",
      " 'response': 1,\n",
      " 'survey': 2,\n",
      " 'time': 3,\n",
      " 'trees': 12,\n",
      " 'unordered': 13,\n",
      " 'user': 4,\n",
      " 'widths': 21}\n",
      "Dictionary<22 unique tokens: ['opinion', 'response', 'survey', 'time', 'user']...>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the Bag of Words\n",
    "Bag of Words (BoW) is a common way of representing text data. It describes the occurrence of words within a document."
   ],
   "id": "ba51309b5eb4ee9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.461405Z",
     "start_time": "2024-09-06T16:43:19.458736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BoW_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint(BoW_corpus)"
   ],
   "id": "4d75e0951162fa99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
      " [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
      " [(9, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
      " [(12, 1), (14, 1), (15, 1), (16, 1)],\n",
      " [(12, 1), (14, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the TF-IDF model\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a way to score the importance of words (or \"terms\") in a document based on how frequently they appear across multiple documents."
   ],
   "id": "9f362586201539d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.509368Z",
     "start_time": "2024-09-06T16:43:19.507Z"
    }
   },
   "cell_type": "code",
   "source": "tfidf = gensim.models.TfidfModel(BoW_corpus)",
   "id": "d9462463b3100866",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:43:19.554681Z",
     "start_time": "2024-09-06T16:43:19.552385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = \"trees graph\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ],
   "id": "f2671e1528c256aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 0.4869354917707381), (14, 0.8734379353188121)]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Similarity Queries\n",
    "Gensim provides a simple interface for performing similarity queries using the model."
   ],
   "id": "5c20ebdab11e9a8f"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "index = gensim.similarities.SparseMatrixSimilarity(tfidf[BoW_corpus], num_features=len(t_corpus))\n",
    "query_document = 'trees system'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "simils = index[tfidf[query_bow]]\n",
    "print(list(enumerate(simils)))"
   ],
   "id": "f7b4cef568c49127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for doc_number, score in sorted(enumerate(simils), key=lambda x: x[1], reverse=True):\n",
    "   print(doc_number, score)"
   ],
   "id": "5a54552338e69dc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
